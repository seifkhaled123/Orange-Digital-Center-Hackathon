{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63325fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4640267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e68995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scraping Page (Collected: 0) ---\n",
      "[1] Yes | Large terrace, air conditionin...\n",
      "--- Scraping Page (Collected: 1) ---\n",
      "[2] Yes | Sweett | Monsigny II...\n",
      "[3] Yes | Superb AC apartment Center of ...\n",
      "[4] Yes | Babylon Grands Boulevards...\n",
      "[5] Yes | Luxurious 3BD with 3BR and AC...\n",
      "[6] Yes | Merveil - Luxury Suite - Marai...\n",
      "[7] Yes | Merveil - Signature Suite - Ei...\n",
      "[8] Yes | LivinParis NEW Luxury A/C 3 Be...\n",
      "[9] Yes | Edgar Suites Martyrs - Lebas 1...\n",
      "[10] Yes | Joie Paris Penthouse Arago...\n",
      "[11] Yes | Edgar Suites Louvre - Day 101...\n",
      "[12] Yes | Edgar Suites Louvre - Day 303...\n",
      "[13] Yes | Edgar Suites Tour Eiffel â€“ Car...\n",
      "[14] Yes | The Residence old Marais: Pati...\n",
      "\n",
      "Completed! Total scraped: 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mis_superhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname[:\u001b[32m30\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Random sleep to look human\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Close tab and return\u001b[39;00m\n\u001b[32m     91\u001b[39m driver.close()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Standardizes formatting for prices\n",
    "def clean_price(price_text):\n",
    "    if not price_text: return \"N/A\"\n",
    "    return \"\".join(filter(str.isdigit, price_text))\n",
    "\n",
    "URL = \"https://www.airbnb.com/s/Paris/homes?refinement_paths%5B%5D=%2Fhomes&date_picker_type=calendar&search_type=search_query&flexible_trip_lengths%5B%5D=one_week&monthly_start_date=2026-02-01&monthly_length=3&monthly_end_date=2026-05-01&price_filter_input_type=2&channel=EXPLORE&price_filter_num_nights=5&min_bedrooms=3&selected_filter_order%5B%5D=min_bedrooms%3A3&update_selected_filters=false\"\n",
    "\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "service = ChromeService(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "all_data = []\n",
    "target_count = 50\n",
    "\n",
    "try:\n",
    "    driver.get(URL)\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "\n",
    "    while len(all_data) < target_count:\n",
    "        print(f\"--- Scraping Page (Collected: {len(all_data)}) ---\")\n",
    "        \n",
    "        # 1. Wait for cards\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div[data-testid='card-container']\")))\n",
    "        \n",
    "        # 2. Collect URLs from current page\n",
    "        listings = driver.find_elements(By.CSS_SELECTOR, \"div[data-testid='card-container']\")\n",
    "        listing_urls = []\n",
    "        \n",
    "        for l in listings:\n",
    "            try:\n",
    "                url = l.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                listing_urls.append(url)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # 3. Store main window handle\n",
    "        main_window = driver.current_window_handle\n",
    "\n",
    "        # 4. Visit each URL\n",
    "        for url in listing_urls:\n",
    "            if len(all_data) >= target_count:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                # Open new tab via JS (Faster/Cleaner)\n",
    "                driver.execute_script(f\"window.open('{url}', '_blank');\")\n",
    "                driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "                # --- STABLE SCRAPING LOGIC ---\n",
    "                \n",
    "                # Wait for the H1 (Title) to ensure page load\n",
    "                wait.until(EC.presence_of_element_located((By.TAG_NAME, \"h1\")))\n",
    "                \n",
    "                # A. Scrape Name\n",
    "                try:\n",
    "                    name = driver.find_element(By.TAG_NAME, \"h1\").text\n",
    "                except:\n",
    "                    name = \"No Title\"\n",
    "\n",
    "                # B. Scrape Superhost (Look for the text, not the class)\n",
    "                # This XPath searches the whole page for the text \"Superhost\"\n",
    "\n",
    "                superhost_indicators = driver.find_elements(By.XPATH, \"//*[contains(text(), 'Superhost')]\")\n",
    "                is_superhost = \"Yes\" if len(superhost_indicators) > 0 else \"No\"\n",
    "\n",
    "                # C. Scrape Price (This is tricky on Detail pages, easier on Search pages)\n",
    "                # We look for the \"price per night\" element usually found in the booking sidebar\n",
    "                price = \"N/A\"\n",
    "                try:\n",
    "                    # Look for element with \"$\" text inside the booking sidebar or sticky header\n",
    "                    price_element = driver.find_element(By.XPATH, \"//div[contains(@data-section-id, 'BOOK_IT')]//span[contains(text(), '$')]\")\n",
    "                    price = price_element.text\n",
    "                except:\n",
    "                    # Fallback: Capture it from the source loosely\n",
    "                    pass\n",
    "\n",
    "                all_data.append({\n",
    "                    \"Name\": name,\n",
    "                    \"Price\": price,\n",
    "                    \"Superhost\": is_superhost,\n",
    "                    \"URL\": url\n",
    "                })\n",
    "                \n",
    "                print(f\"[{len(all_data)}] {is_superhost} | {name[:30]}...\")\n",
    "\n",
    "                # Random sleep to look human\n",
    "                time.sleep(random.uniform(1.5, 3.0))\n",
    "\n",
    "                # Close tab and return\n",
    "                driver.close()\n",
    "                driver.switch_to.window(main_window)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Skipping listing due to error: {e}\")\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(main_window)\n",
    "                continue\n",
    "\n",
    "        # 5. Pagination Logic\n",
    "        if len(all_data) < target_count:\n",
    "            try:\n",
    "                next_btn = driver.find_element(By.CSS_SELECTOR, \"a[aria-label='Next']\")\n",
    "                driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "                time.sleep(5) # Allow next page to load\n",
    "            except:\n",
    "                print(\"No next page found or target reached.\")\n",
    "                break\n",
    "\n",
    "finally:\n",
    "    print(f\"\\nCompleted! Total scraped: {len(all_data)}\")\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
